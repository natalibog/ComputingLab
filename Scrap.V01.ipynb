{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Program takes list of protein identifiers \"3d.list\" and retrieves their protein and nucleotide sequences \\nfrom the protein database webpage \"http://uniprot.org\"\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Program takes list of protein identifiers \"3d.list\" and retrieves their protein and nucleotide sequences \n",
    "from the protein database webpage \"http://uniprot.org\"\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import threading\n",
    "import queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL constants\n",
    "START_URL = 'https://www.uniprot.org/uniprot/'\n",
    "new_url1 = 'https://www.ebi.ac.uk/ena/data/view/'\n",
    "new_url2 = '&display=xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(queue_ids, queue_sequences):\n",
    "    \"\"\" Get UniProtIds from queue_ids and put to queue_sequences sequences of proteins and CDS\n",
    "    \"\"\"\n",
    "    while not queue_ids.empty():\n",
    "        # Get next UniProtId\n",
    "        uniprot_id = queue_ids.get()\n",
    "        url = START_URL + uniprot_id\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "        # Find all CDS ids\n",
    "        t = soup.find_all('a',{'class':\"embl_cds\"})\n",
    "\n",
    "        # Put all CDS ids into CDS list. \n",
    "        cds = []\n",
    "        for i in t:\n",
    "            n = i.get_text()\n",
    "            new = n[:-2]\n",
    "            cds.append(new)\n",
    "\n",
    "        # In rear cases CDS records are absent then we skip to the next UniProtId\n",
    "        if cds == []:\n",
    "            continue\n",
    "\n",
    "        # Retrieve web-page with CDS\n",
    "        # In this vertion of program we are going to use just the first CDS, \n",
    "        # but in the future we are going to use all of them.\n",
    "        cds_url = new_url1 + cds[0] + new_url2\n",
    "        cds_res = requests.get(cds_url)\n",
    "        cds_soup = BeautifulSoup(cds_res.text, \"lxml\")\n",
    "\n",
    "        # Amino acid sequence is under the field 'value', the last instance\n",
    "        cds_t = cds_soup.find_all('value')\n",
    "        if len(cds_t) == 0:\n",
    "            continue\n",
    "        aa_sequence = ''.join(cds_t[-1].get_text().split())\n",
    "        nucl_sequence = ''.join(cds_soup.find('sequence').get_text().split())\n",
    "        queue_sequences.put((uniprot_id, aa_sequence, nucl_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of threads\n",
    "num_threads = 32\n",
    "\n",
    "# Counting time\n",
    "start = time.time()\n",
    "\n",
    "# Here we open the list of proteins IDs which we are interested in\n",
    "fh = open(\"3d.list\",\"r\")\n",
    "readFile = fh.read()\n",
    "uniprot_ids = readFile.split()\n",
    "fh.close()\n",
    "\n",
    "# Initializing queues\n",
    "queue_ids = queue.Queue()\n",
    "queue_sequences = queue.Queue()\n",
    "\n",
    "# Get list of UniProtIds from the file. Here the list is already given\n",
    "for uniprot_id in uniprot_ids:\n",
    "    queue_ids.put(uniprot_id)\n",
    "\n",
    "# Starting threads \n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    t = threading.Thread(target=worker, args=(queue_ids, queue_sequences))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    \n",
    "# Guarantee that all threads are finished\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Print results in cvs format\n",
    "outFile = open(\"idProteinNucleotide.csv\",\"w\")\n",
    "outId = []\n",
    "while not queue_sequences.empty():\n",
    "    uniprot_id, aa_sequence, nucl_sequence = queue_sequences.get()\n",
    "    print(\"{0}, {1}, {2}\".format(uniprot_id, aa_sequence, nucl_sequence), file = outFile)\n",
    "    outId.append(uniprot_id)\n",
    "outFile.close()\n",
    "\n",
    "# Reporting time\n",
    "print(\"Working time:\", round(time.time() - start), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
